mport weka.clusterers.EM;
import weka.core.Instance;
import weka.core.Instances;
import weka.core.converters.ArffLoader;
import weka.clusterers.Cobweb;
import weka.filters.Filter;
import weka.filters.unsupervised.attribute.Remove;

import java.io.File;

/**
 * This example trains Cobweb incrementally on data obtained
 * from the ArffLoader.
 *
 * @author FracPete (fracpete at waikato dot ac dot nz)
 */
public class IncrementalClusterer {

    /**
     * Expects an ARFF file as first argument.
     *
     * @param args        the commandline arguments
     * @throws Exception  if something goes wrong
     */
    public static void main(String[] args) throws Exception {
        // load data
        ArffLoader loader = new ArffLoader();
        loader.setFile(new File("./.arffs/iris.arff"));
        Instances structure = loader.getStructure();


//        // train Cobweb
//        Cobweb cw = new Cobweb();
//        cw.buildClusterer(structure);
//        Instance current;
//        while ((current = loader.getNextInstance(structure)) != null)
//            cw.updateClusterer(current);
//        cw.updateFinished();


        // train EM
        EM clusterer = new EM();
        clusterer.buildClusterer(structure);

        // output generated model
        System.out.println(clusterer);
    }
}
